#!/bin/bash
#SBATCH --array=1-15%5
#SBATCH --cpus-per-task=2
#SBATCH --output=logs/sDDTP/noval-sDDTP.%A.%a.out
#SBATCH --error=logs/sDDTP/noval-sDDTP.%A.%a.err
#SBATCH --gres=gpu:1
#SBATCH --job-name=noval-sDDTP
#SBATCH --mem=10GB
module load anaconda/3
conda activate final_env

cd ~/theoretical_framework_for_target_propagation

orion -v hunt -n noval-sDDTP python main.py \
--lr~'loguniform(1e-3, 1e-1,shape=4)' \
--lr_fb~'loguniform(1e-4, 1e-1)' \
--sigma~'loguniform(1e-5, 1e-2,shape=4)' \
--batch_size~'uniform(100, 200, discrete=True)' \
--feedback_wd~'loguniform(1e-5, 1e-3)' \
--nb_feedback_iterations '1, 1, 1, 1' \
--epsilon~'loguniform(1e-8, 1e-4,shape=4)' \
--epsilon_fb~'loguniform(1e-8, 1e-6)' \
--normalize_lr  \
--target_stepsize~'loguniform(1e-2, 1e-1)' \
--network_type DDTPConvCIFAR \
--initialization xavier_normal \
--fb_activation linear \
--optimizer~"choices(['SGD','Adam'])"  \
--momentum 0.9 \
--parallel  \
--epochs_fb 10 \
--not_randomized \
--not_randomized_fb \
--extra_fb_minibatches 0 \
--extra_fb_epochs 1 \
--double_precision \
--hidden_activation tanh \
--output_activation softmax  \
--random_seed~'uniform(0, 200, discrete=True)' \
--gn_damping 0 \
--log_interval 100 \
--out_dir logs/sDDTP/tuning/ \
--scheduler \
--beta1 0.9 \
--beta1_fb 0.9 \
--beta2 0.999 \
--beta2_fb 0.999 \
--dataset cifar10 \
--epochs 90 \
--num_hidden 2 \
--no_val_set
